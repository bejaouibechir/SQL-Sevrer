# Execices Jobs, Schedules, Alertes, Proxy, Operators
Voici une nouvelle version des **20 exercices** pour le thème **Jobs, Schedules, Alertes, Proxy, Operators**, prenant en compte vos remarques. Chaque exercice inclut une configuration de **Papercut SMTP**, un test avec **Database Mail**, et des exemples **ETL réalistes et intuitifs** avec plusieurs étapes d’extraction, transformation, et chargement.

---

### **Préambule : Installation et configuration de Papercut SMTP**

---

#### **Installation de Papercut SMTP** :
1. **Téléchargez Papercut SMTP** depuis [ce lien GitHub](https://github.com/ChangemakerStudios/Papercut-SMTP/releases).
2. Décompressez le fichier téléchargé et lancez `Papercut.SMTP.exe`.
3. L’interface de Papercut SMTP doit s’afficher, indiquant qu’il est prêt à capturer les e-mails sur le port **25**.

---

#### **Configuration dans SQL Server** :
1. Activez **Database Mail** dans SQL Server :
   ```sql
   EXEC sp_configure 'show advanced options', 1;
   RECONFIGURE;
   EXEC sp_configure 'Database Mail XPs', 1;
   RECONFIGURE;
   ```
2. Dans **SSMS**, configurez un compte Database Mail avec les paramètres suivants :
   - **Account name** : PapercutAccount
   - **E-mail address** : `me780411@gmail.com`
   - **Display name** : Papercut SMTP
   - **Reply e-mail** : `me780411@gmail.com`
   - **Server name** : `localhost`
   - **Port** : `25`
   - **Authentication** : Anonyme
3. Créez un profil nommé `PapercutProfile` et testez avec :
   ```sql
   EXEC msdb.dbo.sp_send_dbmail
       @profile_name = 'PapercutProfile',
       @recipients = 'me780411@gmail.com',
       @subject = 'Test Email from Database Mail',
       @body = 'This is a test email sent using Papercut SMTP.';
   ```

Vérifiez l'e-mail dans l'interface Papercut.

---

### **Exercices 1 à 5 : Jobs ETL (Graphique)**

---

#### **Exercice 1 : Sauvegarder des données dans un fichier JSON**
- **Objectif** : Extraire des données de `Sales.SalesOrderHeader` et les sauvegarder dans un fichier JSON.
- **Étapes** :
  1. Créez un Job nommé **BackupSalesData**.
  2. **Étape 1 : Extraction des données** :
     - **Commande T-SQL** :
       ```sql
       SELECT * 
       FROM AdventureWorks2022.Sales.SalesOrderHeader
       WHERE OrderDate >= DATEADD(YEAR, -1, GETDATE());
       ```
  3. **Étape 2 : Sauvegarde des données dans un fichier JSON** :
     - **Commande T-SQL** :
       ```sql
       SELECT *
       FROM AdventureWorks2022.Sales.SalesOrderHeader
       FOR JSON AUTO, ROOT('SalesOrders')
       INTO OUTFILE 'C:\Exports\SalesOrders.json';
       ```

---

#### **Exercice 2 : Fusionner deux tables et sauvegarder dans une nouvelle table**
- **Objectif** : Faire une jointure entre `Sales.SalesOrderHeader` et `Sales.SalesOrderDetail`, puis charger les données dans une nouvelle table.
- **Étapes** :
  1. Créez un Job nommé **MergeSalesData**.
  2. **Étape 1 : Créer la table de destination** :
     - **Commande T-SQL** :
       ```sql
       CREATE TABLE SalesMerged (
           OrderID INT,
           OrderDate DATE,
           ProductID INT,
           Quantity INT,
           TotalDue DECIMAL(18, 2)
       );
       ```
  3. **Étape 2 : Faire la jointure et charger les données** :
     - **Commande T-SQL** :
       ```sql
       INSERT INTO SalesMerged (OrderID, OrderDate, ProductID, Quantity, TotalDue)
       SELECT soh.SalesOrderID, soh.OrderDate, sod.ProductID, sod.OrderQty, soh.TotalDue
       FROM AdventureWorks2022.Sales.SalesOrderHeader soh
       JOIN AdventureWorks2022.Sales.SalesOrderDetail sod
       ON soh.SalesOrderID = sod.SalesOrderID;
       ```

---

#### **Exercice 3 : Extraire, trier et sauvegarder dans une base spécifique**
- **Objectif** : Extraire les données de `SalesOrderHeader`, trier par montant décroissant et sauvegarder dans une base secondaire.
- **Étapes** :
  1. Créez une base secondaire `ETL_Destination` :
     ```sql
     CREATE DATABASE ETL_Destination;
     ```
  2. Créez un Job nommé **SortedSalesETL**.
  3. **Étape 1 : Extraction des données** :
     - **Commande T-SQL** :
       ```sql
       SELECT * 
       INTO TempSortedSales
       FROM AdventureWorks2022.Sales.SalesOrderHeader
       ORDER BY TotalDue DESC;
       ```
  4. **Étape 2 : Charger dans `ETL_Destination`** :
     - **Commande T-SQL** :
       ```sql
       USE ETL_Destination;
       SELECT * INTO SortedSales FROM TempSortedSales;
       ```

---

#### **Exercice 4 : Filtrer et exporter des données dans un fichier CSV**
- **Objectif** : Filtrer les commandes supérieures à 5000$ et exporter dans un fichier CSV.
- **Étapes** :
  1. Créez un Job nommé **ExportHighValueOrders**.
  2. **Étape 1 : Filtrer les données** :
     - **Commande T-SQL** :
       ```sql
       SELECT * INTO HighValueOrders
       FROM AdventureWorks2022.Sales.SalesOrderHeader
       WHERE TotalDue > 5000;
       ```
  3. **Étape 2 : Exporter en CSV** :
     - **Commande PowerShell simple** :
       ```powershell
       bcp "SELECT * FROM AdventureWorks2022.dbo.HighValueOrders" queryout "C:\Exports\HighValueOrders.csv" -c -T
       ```

---

#### **Exercice 5 : Créer une table agrégée des ventes annuelles**
- **Objectif** : Agréger les ventes par année et sauvegarder dans une nouvelle table.
- **Étapes** :
  1. Créez un Job nommé **AggregateSalesByYear**.
  2. **Étape 1 : Créer la table agrégée** :
     - **Commande T-SQL** :
       ```sql
       CREATE TABLE YearlySales (
           Year INT,
           TotalSales DECIMAL(18, 2)
       );
       ```
  3. **Étape 2 : Charger les données agrégées** :
     - **Commande T-SQL** :
       ```sql
       INSERT INTO YearlySales (Year, TotalSales)
       SELECT YEAR(OrderDate), SUM(TotalDue)
       FROM AdventureWorks2022.Sales.SalesOrderHeader
       GROUP BY YEAR(OrderDate);
       ```

---

### **Exercices 6 à 10 : Introduction aux Schedules et Database Mail**

---

#### **Exercice 6 : Planifier un Job pour exécuter tous les jours**
- **Objectif** : Automatiser un job pour qu’il s’exécute quotidiennement à 1h.
- **Instructions** :
  1. Créez un Schedule nommé `DailySchedule`.
  2. Associez le Job **AggregateSalesByYear** au Schedule.

---

#### **Exercice 7 : Configurer une alerte en cas d’échec**
- **Objectif** : Recevoir un e-mail en cas d’échec.
- **Instructions** :
  1. Associez une alerte à un **Operator** (`AdminOperator`) pour notifier en cas d’échec.

---

Les **exercices 11 à 20** combineront des Schedules, Proxy, et Operators avec des scénarios avancés. Voulez-vous que je les détaille ?

### **Exercices 11 à 20 : Scénarios avancés avec Schedules, Proxy, Alertes, et Operators**

### **Exercice 11 : Job avec Schedule pour surveiller les ventes mensuelles**
- **Objectif** : Planifier un Job pour extraire les ventes mensuelles, les agréger, et charger les résultats dans une table dédiée.
- **Étapes** :
  1. Créez un Job nommé **MonthlySalesMonitor**.
  2. **Étape 1 : Extraire les ventes mensuelles** :
     - **Commande T-SQL** :
       ```sql
       SELECT * INTO MonthlySales
       FROM AdventureWorks2022.Sales.SalesOrderHeader
       WHERE OrderDate >= DATEADD(MONTH, -1, GETDATE());
       ```
  3. **Étape 2 : Agréger les données** :
     - **Commande T-SQL** :
       ```sql
       SELECT COUNT(*) AS OrderCount, SUM(TotalDue) AS TotalSales
       INTO MonthlyAggregatedSales
       FROM MonthlySales;
       ```
  4. Ajoutez un Schedule pour exécuter ce Job le 1er de chaque mois à 2h00.

---

### **Exercice 12 : Créer une alerte pour les ventes exceptionnelles**
- **Objectif** : Surveiller les commandes dépassant 50 000$ et notifier par e-mail.
- **Étapes** :
  1. Créez une table d’audit :
     ```sql
     CREATE TABLE HighValueOrderLog (
         OrderID INT,
         TotalDue DECIMAL(18, 2),
         DetectedAt DATETIME
     );
     ```
  2. Créez un Job **HighValueAlert** :
     - **Étape 1 : Identifier les commandes** :
       ```sql
       INSERT INTO HighValueOrderLog (OrderID, TotalDue, DetectedAt)
       SELECT SalesOrderID, TotalDue, GETDATE()
       FROM AdventureWorks2022.Sales.SalesOrderHeader
       WHERE TotalDue > 50000;
       ```
     - **Étape 2 : Notifier via Database Mail** si des commandes sont détectées :
       ```sql
       IF EXISTS (SELECT 1 FROM HighValueOrderLog WHERE DetectedAt = CAST(GETDATE() AS DATE))
       BEGIN
           EXEC msdb.dbo.sp_send_dbmail
               @profile_name = 'PapercutProfile',
               @recipients = 'me780411@gmail.com',
               @subject = 'High Value Order Detected',
               @body = 'A sales order exceeding $50,000 has been logged.';
       END;
       ```

---

### **Exercice 13 : Job sécurisé avec Proxy pour exporter les logs SQL**
- **Objectif** : Utiliser un Proxy pour exécuter un Job exportant les logs SQL Server.
- **Étapes** :
  1. Configurez une Credential et associez-la à un Proxy :
     ```sql
     CREATE CREDENTIAL ProxyCredential 
     WITH IDENTITY = 'WindowsUserName', SECRET = 'Password123';
     EXEC sp_add_proxy @proxy_name = 'LogExportProxy', @credential_name = 'ProxyCredential';
     ```
  2. Créez un Job nommé **ExportSQLLogs** :
     - **Étape 1 : Collecter les logs** :
       ```sql
       SELECT * INTO SQLServerLogs
       FROM sys.dm_exec_requests;
       ```
     - **Étape 2 : Exporter les logs avec BCP** :
       ```powershell
       bcp "SELECT * FROM SQLServerLogs" queryout "C:\Logs\SQLServerLogs.csv" -c -T
       ```

---

### **Exercice 14 : Job multi-steps pour surveiller la fragmentation des index**
- **Objectif** : Détecter les index fragmentés et reconstruire les plus critiques.
- **Étapes** :
  1. Créez un Job **IndexFragmentationMonitor**.
  2. **Étape 1 : Identifier les index fragmentés** :
     - **Commande T-SQL** :
       ```sql
       SELECT OBJECT_NAME(object_id) AS TableName, 
              index_id, 
              avg_fragmentation_in_percent
       INTO FragmentedIndexes
       FROM sys.dm_db_index_physical_stats(DB_ID(), NULL, NULL, NULL, 'LIMITED')
       WHERE avg_fragmentation_in_percent > 30;
       ```
  3. **Étape 2 : Reconstruire les index** :
     - **Commande T-SQL** :
       ```sql
       DECLARE @TableName NVARCHAR(255), @IndexID INT;
       DECLARE CursorIndex CURSOR FOR
       SELECT TableName, index_id FROM FragmentedIndexes;
       OPEN CursorIndex;
       FETCH NEXT FROM CursorIndex INTO @TableName, @IndexID;
       WHILE @@FETCH_STATUS = 0
       BEGIN
           EXEC ('ALTER INDEX ALL ON ' + @TableName + ' REBUILD');
           FETCH NEXT FROM CursorIndex INTO @TableName, @IndexID;
       END;
       CLOSE CursorIndex;
       DEALLOCATE CursorIndex;
       ```

---

### **Exercice 15 : Surveillance de l’espace disque**
- **Objectif** : Détecter si l’espace disque est insuffisant et envoyer une notification.
- **Étapes** :
  1. Créez un Job **DiskSpaceMonitor**.
  2. **Étape 1 : Vérifiez l’espace disque** :
     ```sql
     SELECT DISTINCT volume_mount_point, available_bytes / (1024 * 1024) AS FreeSpaceMB
     INTO DiskSpaceStatus
     FROM sys.dm_os_volume_stats(DB_ID(), 1)
     WHERE available_bytes < 500 * 1024 * 1024; -- Moins de 500MB
     ```
  3. **Étape 2 : Envoyez une alerte** si la condition est remplie :
     ```sql
     IF EXISTS (SELECT 1 FROM DiskSpaceStatus)
     BEGIN
         EXEC msdb.dbo.sp_send_dbmail
             @profile_name = 'PapercutProfile',
             @recipients = 'me780411@gmail.com',
             @subject = 'Disk Space Alert',
             @body = 'The available disk space is below 500MB.';
     END;
     ```

---

### **Exercice 16 : Automatiser un ETL complet**
- **Objectif** : Extraire les ventes, les transformer en regroupant par produit, et charger dans une table.
- **Étapes** :
  1. Créez un Job nommé **ProductSalesETL**.
  2. **Étape 1 : Extraction des ventes** :
     ```sql
     SELECT * INTO TempSalesData
     FROM AdventureWorks2022.Sales.SalesOrderDetail;
     ```
  3. **Étape 2 : Transformation des données** :
     ```sql
     SELECT ProductID, SUM(LineTotal) AS TotalSales, COUNT(*) AS OrderCount
     INTO TransformedSales
     FROM TempSalesData
     GROUP BY ProductID;
     ```
  4. **Étape 3 : Chargement** :
     ```sql
     INSERT INTO AggregatedProductSales
     SELECT * FROM TransformedSales;
     ```

---
Merci pour votre retour ! Je vais revoir les exercices 17, 18, 19, et 20 pour **ajouter des détails concrets** et proposer des scénarios où les **résultats sont immédiatement observables**. Ces cas seront centrés sur des tâches **ETL** et des utilisations pertinentes et tangibles.

---

### **Exercice 17 : Simuler un échec de Job et vérifier l'alerte**
- **Objectif** : Simuler un échec intentionnel pour valider la configuration d’une alerte avec Database Mail.
- **Étapes** :
  1. **Configurer une alerte en cas d’échec** :
     - Créez une alerte dans **SQL Server Agent** :
       - **Nom** : `JobFailureAlert`.
       - **Type** : SQL Server Event Alert.
       - **ID d’erreur** : 50000 (Erreur utilisateur personnalisée).
     - Associez cette alerte à un **Operator** (par exemple : `AdminOperator`).

  2. **Créer un Job qui échoue volontairement** :
     - Créez un Job nommé **SimulateFailure**.
     - Ajoutez une étape avec une commande T-SQL incorrecte :
       ```sql
       SELECT * FROM NonExistentTable; -- Génère une erreur
       ```
  3. **Tester l’exécution** :
     - Lancez le Job manuellement.
     - Vérifiez que l’erreur est capturée dans **SQL Server Agent**.
     - Vérifiez que l’e-mail d’alerte est reçu dans **Papercut SMTP**.

  4. **Résultat attendu** :
     - Une alerte est envoyée avec l’erreur capturée :
       ```
       Job 'SimulateFailure' failed at Step 1 with error: Invalid object name 'NonExistentTable'.
       ```

---

### **Exercice 18 : Planifier une tâche ETL avec un Proxy**
- **Objectif** : Utiliser un Proxy pour automatiser un ETL consistant à extraire, transformer, et charger des données dans une base secondaire.
- **Étapes** :
  1. **Créer un Proxy sécurisé** :
     - Configurez une Credential et associez-la à un Proxy :
       ```sql
       CREATE CREDENTIAL ProxyCredential 
       WITH IDENTITY = 'WindowsUserName', SECRET = 'Password123';
       EXEC sp_add_proxy 
           @proxy_name = 'ETLProxy', 
           @credential_name = 'ProxyCredential';
       ```

  2. **Créer un Job multi-steps avec le Proxy** :
     - Nom : **AutomatedETL**.
     - Assurez-vous que le Proxy est assigné à chaque étape.

     **Étape 1 : Extraction des données** :
     ```sql
     SELECT * INTO TempSalesData
     FROM AdventureWorks2022.Sales.SalesOrderHeader
     WHERE OrderDate >= DATEADD(MONTH, -1, GETDATE());
     ```

     **Étape 2 : Transformation des données** :
     ```sql
     SELECT CustomerID, SUM(TotalDue) AS TotalSpent
     INTO TransformedSalesData
     FROM TempSalesData
     GROUP BY CustomerID;
     ```

     **Étape 3 : Chargement des données** :
     ```sql
     INSERT INTO ETL_Destination.dbo.AggregatedSales
     SELECT * FROM TransformedSalesData;
     ```

  3. **Planifier le Job** :
     - Associez un Schedule pour l’exécution quotidienne à 3h00.

  4. **Tester l’exécution** :
     - Lancez le Job manuellement.
     - Vérifiez les données chargées dans la table `ETL_Destination.dbo.AggregatedSales`.

  5. **Résultat attendu** :
     - Les données sont extraites, transformées, et chargées dans la base secondaire.

---

### **Exercice 19 : Auditer les permissions des utilisateurs et exporter dans un fichier**
- **Objectif** : Créer un Job pour auditer les permissions des utilisateurs et sauvegarder les résultats dans un fichier CSV.
- **Étapes** :
  1. **Créer un Job nommé `AuditUserPermissions`** :
     - **Étape 1 : Collecter les permissions utilisateurs** :
       ```sql
       SELECT dp.name AS UserName, 
              o.name AS ObjectName, 
              p.permission_name AS PermissionType
       INTO UserPermissionsAudit
       FROM sys.database_permissions p
       JOIN sys.objects o ON p.major_id = o.object_id
       JOIN sys.database_principals dp ON p.grantee_principal_id = dp.principal_id;
       ```

     - **Étape 2 : Exporter les données** dans un fichier CSV :
       ```powershell
       bcp "SELECT * FROM UserPermissionsAudit" queryout "C:\Exports\UserPermissions.csv" -c -T
       ```

  2. **Résultat attendu** :
     - Un fichier CSV est généré à l’emplacement `C:\Exports\UserPermissions.csv`.
     - Le contenu du fichier est immédiatement vérifiable dans Excel.

---

### **Exercice 20 : Détecter les transactions longues et les charger dans une table**
- **Objectif** : Identifier les transactions dépassant une durée donnée et charger les résultats dans une table d’audit.
- **Étapes** :
  1. **Créer une table d’audit des transactions longues** :
     ```sql
     CREATE TABLE LongRunningTransactionsAudit (
         TransactionID BIGINT,
         StartTime DATETIME,
         DurationMinutes INT
     );
     ```

  2. **Créer un Job nommé `MonitorLongTransactions`** :
     - **Étape 1 : Identifier les transactions longues** :
       ```sql
       INSERT INTO LongRunningTransactionsAudit (TransactionID, StartTime, DurationMinutes)
       SELECT transaction_id, start_time, DATEDIFF(MINUTE, start_time, GETDATE()) AS DurationMinutes
       FROM sys.dm_tran_active_transactions
       WHERE DATEDIFF(MINUTE, start_time, GETDATE()) > 10;
       ```

     - **Étape 2 : Envoyer une alerte si des transactions sont détectées** :
       ```sql
       IF EXISTS (SELECT 1 FROM LongRunningTransactionsAudit WHERE DurationMinutes > 10)
       BEGIN
           EXEC msdb.dbo.sp_send_dbmail
               @profile_name = 'PapercutProfile',
               @recipients = 'me780411@gmail.com',
               @subject = 'Long Running Transaction Alert',
               @body = 'One or more transactions have exceeded the allowed duration.';
       END;
       ```

  3. **Résultat attendu** :
     - Les transactions longues sont insérées dans la table `LongRunningTransactionsAudit`.
     - Une alerte est envoyée pour signaler les cas détectés.

   ---
  # Appels sequenciels de Jobs

Oui, c'est **partiellement configurable graphiquement** dans SQL Server Management Studio (SSMS). Cependant, certaines approches nécessitent un script pour compléter la configuration. Voici les options graphiques disponibles :

---

### 1. **Enchaîner les jobs via des étapes supplémentaires**
- Ouvrez le premier job dans **SQL Server Agent** :
  - **Clic droit** sur le job → **Propriétés**.
  - Allez à l'onglet **Steps**.
  - Ajoutez une étape finale avec un type de commande **T-SQL**.
  - Utilisez `EXEC msdb.dbo.sp_start_job N'NomDuDeuxièmeJob';`.
  - Configurez cette étape pour s'exécuter uniquement après le succès des étapes précédentes.
  - Sauvegardez les modifications.

---

### 2. **Configurer des notifications pour déclencher manuellement le second job**
- Configurez le premier job pour **envoyer une notification** (succès ou échec) :
  - Dans le job, allez dans **Steps** → **Advanced** → Configurez **On success action** à "Notify Operator".
  - Créez un **Operator** dans SQL Server Agent.
  - Manuellement, vous pourrez utiliser cette notification pour gérer un déclencheur externe.

---

### 3. **Créer un Job Parent pour enchaîner les deux**
- Créez un "job parent" :
  - Clic droit sur **Jobs** → **New Job**.
  - Ajoutez une première étape pour exécuter le premier job : 
    ```sql
    EXEC msdb.dbo.sp_start_job N'Job1';
    ```
  - Ajoutez une deuxième étape pour exécuter le second job :
    ```sql
    EXEC msdb.dbo.sp_start_job N'Job2';
    ```
  - Configurez la **gestion des étapes** pour ne passer à la suivante qu'en cas de succès.


---
# Etude de Cas: Planification des employees à l'echell regional
Voici un tutoriel détaillé pour réaliser ce workflow avec SQL Server Management Studio (SSMS). Le tutoriel est divisé en étapes claires avec des scripts et instructions pour configurer les **jobs** graphiquement.

---

## **1. Création de la base de données `nationaldb` et de la table `Employee`**
### Script pour la base et la table :
```sql
-- Création de la base de données nationaldb si elle n'existe pas
IF NOT EXISTS (SELECT name FROM sys.databases WHERE name = 'nationaldb')
BEGIN
    CREATE DATABASE nationaldb;
END;

-- Sélection de la base
USE nationaldb;

-- Création de la table Employee si elle n'existe pas
IF NOT EXISTS (SELECT * FROM sys.tables WHERE name = 'Employee')
BEGIN
    CREATE TABLE Employee (
        id INT PRIMARY KEY IDENTITY(1,1),
        nom NVARCHAR(20),
        age INT,
        situation_familiale NVARCHAR(10),
        genre NVARCHAR(10),
        gouvernerat NVARCHAR(20)
    );
END;
```

---

## **2. Insertion des données pour le test**
### Script pour insérer des données :
```sql
INSERT INTO Employee (nom, age, situation_familiale, genre, gouvernerat)
VALUES 
('Ahmed', 30, 'marrié', 'male', 'Tunis'),
('Amira', 25, 'célibataire', 'femelle', 'Sfax'),
('Houssem', 40, 'marrié', 'male', 'Kasserine'),
('Sami', 35, 'célibataire', 'male', 'Bizerte'),
('Mouna', 28, 'marriée', 'femelle', 'Sfax'),
('Foued', 33, 'célibataire', 'male', 'Kasserine'),
('Syrine', 23, 'célibataire', 'femelle', 'Tozeur'),
('Salem', 45, 'marrié', 'male', 'Ben Arous');
INSERT INTO Employee (nom, age, situation_familiale, genre, gouvernerat) VALUES
('Ali', 45, 'célibataire', 'femelle', 'Bizerte'),
('Ahmed', 21, 'marié', 'male', 'Ben Arous'),
('Houssem', 49, 'célibataire', 'male', 'Ben Arous'),
('Rami', 28, 'marié', 'femelle', 'Mahdia'),
('Amira', 54, 'marié', 'male', 'Sousse'),
('Yassine', 44, 'célibataire', 'femelle', 'Sousse'),
('Fatma', 18, 'marié', 'femelle', 'Sousse'),
('Mehdi', 42, 'célibataire', 'male', 'Sousse'),
('Mouna', 20, 'marié', 'femelle', 'Sousse'),
('Ahmed', 23, 'marié', 'femelle', 'Kasserine'),
('Oussama', 40, 'marié', 'male', 'Sfax'),
('Sondes', 50, 'célibataire', 'male', 'Kasserine'),
('Sahar', 34, 'marié', 'male', 'Bizerte'),
('Ahmed', 21, 'célibataire', 'male', 'Kasserine'),
('Ahmed', 35, 'célibataire', 'male', 'Bizerte'),
('Sami', 45, 'célibataire', 'male', 'Gabes'),
('Zied', 48, 'célibataire', 'male', 'Sfax'),
('Oussama', 45, 'marié', 'femelle', 'Ben Arous'),
('Mehdi', 25, 'célibataire', 'male', 'Tunis'),
('Syrine', 23, 'célibataire', 'male', 'Tunis'),
('Amira', 42, 'marié', 'male', 'Gabes'),
('Ahmed', 56, 'marié', 'male', 'Tozeur'),
('Fatma', 18, 'marié', 'femelle', 'Sfax'),
('Zied', 47, 'célibataire', 'femelle', 'Gabes'),
('Ahmed', 27, 'célibataire', 'male', 'Gafsa'),
('Hanen', 53, 'célibataire', 'femelle', 'Mahdia'),
('Yassine', 29, 'marié', 'male', 'Tunis'),
('Houssem', 38, 'célibataire', 'femelle', 'Ben Arous'),
('Sahar', 31, 'marié', 'femelle', 'Ariana'),
('Rami', 35, 'marié', 'femelle', 'Gabes'),
('Mouna', 57, 'célibataire', 'femelle', 'Mahdia'),
('Mouna', 50, 'marié', 'femelle', 'Mahdia'),
('Houssem', 31, 'célibataire', 'male', 'Nabeul'),
('Amira', 59, 'marié', 'femelle', 'Sfax'),
('Houssem', 25, 'célibataire', 'male', 'Gabes'),
('Lotfi', 58, 'marié', 'male', 'Sousse'),
('Foued', 41, 'célibataire', 'femelle', 'Ariana'),
('Asma', 40, 'marié', 'femelle', 'Beja'),
('Sahar', 47, 'marié', 'male', 'Gabes'),
('Sami', 28, 'célibataire', 'male', 'Kasserine'),
('Houssem', 36, 'célibataire', 'male', 'Beja'),
('Rami', 30, 'marié', 'femelle', 'Ben Arous'),
('Safa', 38, 'marié', 'male', 'Nabeul'),
('Ahmed', 50, 'marié', 'male', 'Bizerte'),
('Rami', 22, 'marié', 'femelle', 'Sfax'),
('Sami', 58, 'marié', 'male', 'Sousse'),
('Zied', 58, 'marié', 'femelle', 'Tunis'),
('Ahmed', 31, 'célibataire', 'femelle', 'Sfax'),
('Amina', 58, 'célibataire', 'femelle', 'Tozeur'),
('Safa', 24, 'célibataire', 'femelle', 'Ben Arous'),
('Ahmed', 19, 'marié', 'male', 'Tunis'),
('Amina', 24, 'célibataire', 'male', 'Mahdia'),
('Yassine', 18, 'marié', 'male', 'Kasserine'),
('Fatma', 40, 'marié', 'male', 'Nabeul'),
('Lotfi', 39, 'marié', 'femelle', 'Sfax'),
('Sami', 18, 'marié', 'femelle', 'Sfax'),
('Sondes', 24, 'célibataire', 'femelle', 'Sfax'),
('Sondes', 25, 'célibataire', 'male', 'Gafsa'),
('Houssem', 38, 'marié', 'femelle', 'Gafsa'),
('Khaled', 22, 'célibataire', 'male', 'Beja'),
('Asma', 60, 'marié', 'male', 'Gabes'),
('Zied', 34, 'célibataire', 'male', 'Gabes'),
('Salem', 18, 'célibataire', 'femelle', 'Bizerte'),
('Foued', 48, 'célibataire', 'femelle', 'Gabes'),
('Mouna', 53, 'marié', 'femelle', 'Bizerte'),
('Foued', 37, 'célibataire', 'male', 'Gafsa'),
('Sahar', 47, 'marié', 'femelle', 'Ariana'),
('Hanen', 35, 'marié', 'male', 'Gafsa'),
('Zied', 34, 'célibataire', 'male', 'Sfax'),
('Amira', 25, 'marié', 'femelle', 'Sousse');
-- Répétez avec d'autres noms/gouvernorats.
```

---

## **3. Configuration des Jobs Graphiques**

### **3.1 Création du Job Parent**
1. Ouvrez **SQL Server Agent** dans SSMS.
2. Faites un clic droit sur **Jobs** → **New Job**.
3. Configurez les étapes :
   - Étape 1 : **Créer la base de données nationaldb** (utilisez le script ci-dessus).
   - Étape 2 : **Créer la table Employee** (utilisez le script ci-dessus).
   - Étape 3 : **Purger la table Employee si elle contient des données** :
     ```sql
     USE nationaldb;
     DELETE FROM Employee WHERE 1=1;
     ```

---

### **3.2 Création des Jobs Enfants**
#### **Job Fils 1 (Sfax)**
1. Créez un nouveau job et nommez-le `Job_Fils_Sfax`.
2. Configurez les étapes :
   - Étape 1 : Créer la base `regional_sfax_db` si elle n'existe pas.
     ```sql
     IF NOT EXISTS (SELECT name FROM sys.databases WHERE name = 'regional_sfax_db')
     BEGIN
         CREATE DATABASE regional_sfax_db;
     END;
     ```
   - Étape 2 : Créer la table Employee dans `regional_sfax_db`.
     ```sql
     USE regional_sfax_db;
     IF NOT EXISTS (SELECT * FROM sys.tables WHERE name = 'Employee')
     BEGIN
         CREATE TABLE Employee (
             id INT PRIMARY KEY IDENTITY(1,1),
             nom NVARCHAR(20),
             age INT,
             situation_familiale NVARCHAR(10),
             genre NVARCHAR(10),
             gouvernerat NVARCHAR(20)
         );
     END;
     ```
   - Étape 3 : Purger la table si elle contient des données.
     ```sql
     USE regional_sfax_db;
     DELETE FROM Employee WHERE 1=1;
     ```
   - Étape 4 : Remplir la table avec les employés de Sfax :
     ```sql
     USE nationaldb;
     INSERT INTO regional_sfax_db.dbo.Employee (nom, age, situation_familiale, genre, gouvernerat)
     SELECT * FROM Employee WHERE gouvernerat = 'Sfax' OR SOUNDEX(gouvernerat) = SOUNDEX('Sfax');
     ```

#### **Job Fils 2 (Kasserine)**
1. Répétez les étapes du `Job_Fils_Sfax` en remplaçant `Sfax` par `Kasserine` et `regional_sfax_db` par `regional_kasserine_db`.

---

### **3.3 Job Enfant 3 (Autres Gouvernorats)**
1. Créez un job nommé `Job_Fils_Divers`.
2. Configurez les étapes pour créer une base `regional_divers_db`, une table `Employee`, purger les données, puis insérer tous les employés des autres gouvernorats :
   ```sql
   USE nationaldb;
   INSERT INTO regional_divers_db.dbo.Employee (nom, age, situation_familiale, genre, gouvernerat)
   SELECT * FROM Employee WHERE gouvernerat NOT IN ('Sfax', 'Kasserine')
   AND SOUNDEX(gouvernerat) NOT IN (SOUNDEX('Sfax'), SOUNDEX('Kasserine'));
   ```

---

### **3.4 Intégration des Jobs Enfants dans le Job Parent**
1. Retournez dans le **Job Parent**.
2. Ajoutez une étape après la purge pour vérifier les gouvernorats et appeler les jobs enfants :
   - Étape 4 : Lancer `Job_Fils_Sfax` si un gouvernorat correspond à Sfax :
     ```sql
     EXEC msdb.dbo.sp_start_job N'Job_Fils_Sfax';
     ```
   - Étape 5 : Lancer `Job_Fils_Kasserine` si un gouvernorat correspond à Kasserine :
     ```sql
     EXEC msdb.dbo.sp_start_job N'Job_Fils_Kasserine';
     ```
   - Étape 6 : Lancer `Job_Fils_Divers` pour tous les autres gouvernorats :
     ```sql
     EXEC msdb.dbo.sp_start_job N'Job_Fils_Divers';
     ```

---

## **4. Tester le Workflow**
1. Exécutez le **Job Parent** depuis SQL Server Agent.
2. Vérifiez les bases `regional_sfax_db`, `regional_kasserine_db`, et `regional_divers_db` pour confirmer les résultats.

---
   

